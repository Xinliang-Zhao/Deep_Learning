{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "variational autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Xinliang-Zhao/Deep_Learning/blob/master/variational_autoencoder_tensorboard.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "gRmtwdGMnox5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tfd = tf.contrib.distributions\n",
        "\n",
        "LOG_DIR = 'embedded_test_sample'\n",
        "NAME_TO_VISUALISE_VARIABLE = \"mnist_embedding\"\n",
        "\n",
        "path_for_mnist_sprites =  os.path.join(LOG_DIR,'mnistdigits.png')\n",
        "path_for_mnist_metadata =  os.path.join(LOG_DIR,'metadata.tsv')\n",
        "\n",
        "def make_encoder(data, code_size):\n",
        "  x = tf.layers.flatten(data)\n",
        "  x = tf.layers.dense(x, 200, tf.nn.relu)\n",
        "  x = tf.layers.dense(x, 200, tf.nn.relu)\n",
        "  loc = tf.layers.dense(x, code_size)\n",
        "  scale = tf.layers.dense(x, code_size, tf.nn.softplus)\n",
        "  return tfd.MultivariateNormalDiag(loc, scale)\n",
        "\n",
        "\n",
        "def make_prior(code_size):\n",
        "  loc = tf.zeros(code_size)\n",
        "  scale = tf.ones(code_size)\n",
        "  return tfd.MultivariateNormalDiag(loc, scale)\n",
        "\n",
        "\n",
        "def make_decoder(code, data_shape):\n",
        "  x = code\n",
        "  x = tf.layers.dense(x, 200, tf.nn.relu)\n",
        "  x = tf.layers.dense(x, 200, tf.nn.relu)\n",
        "  logit = tf.layers.dense(x, np.prod(data_shape))\n",
        "  logit = tf.reshape(logit, [-1] + data_shape)\n",
        "  return tfd.Independent(tfd.Bernoulli(logit), 2)\n",
        "\n",
        "\n",
        "def plot_codes(fig, ax, codes, labels):\n",
        "  im = ax.scatter(codes[:, 0], codes[:, 1], s=20, c=labels, alpha=1, cmap='viridis')\n",
        "  fig.colorbar(im, ax=ax)\n",
        "  ax.set_aspect('equal')\n",
        "  ax.set_xlim(codes.min() - .1, codes.max() + .1)\n",
        "  ax.set_ylim(codes.min() - .1, codes.max() + .1)\n",
        "  ax.tick_params(\n",
        "      axis='both', which='both', left='off', bottom='off',\n",
        "      labelleft='off', labelbottom='off')\n",
        "\n",
        "\n",
        "def plot_samples(ax, samples):\n",
        "  for index, sample in enumerate(samples):\n",
        "    ax[index].imshow(sample, cmap='gray')\n",
        "    ax[index].axis('off')\n",
        "\n",
        "\n",
        "data = tf.placeholder(tf.float32, [None, 28, 28])\n",
        "\n",
        "make_encoder = tf.make_template('encoder', make_encoder)\n",
        "make_decoder = tf.make_template('decoder', make_decoder)\n",
        "\n",
        "embedding_size = 2\n",
        "# Define the model.\n",
        "prior = make_prior(code_size=embedding_size)\n",
        "posterior = make_encoder(data, code_size=embedding_size)\n",
        "code = posterior.sample()\n",
        "\n",
        "# Define the loss.\n",
        "likelihood = make_decoder(code, [28, 28]).log_prob(data)\n",
        "divergence = tfd.kl_divergence(posterior, prior)\n",
        "elbo = tf.reduce_mean(likelihood - divergence)\n",
        "optimize = tf.train.AdamOptimizer(0.001).minimize(-elbo)\n",
        "\n",
        "samples = make_decoder(prior.sample(10), [28, 28]).mean()\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data/')\n",
        "train_idx = [idx for (idx, label) in enumerate(mnist.train.labels) if label == 1]\n",
        "train_images = mnist.train.images[train_idx]\n",
        "train_labels = mnist.train.labels[train_idx]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_idx), reshuffle_each_iteration=True)\n",
        "train_dataset = train_dataset.batch(100)\n",
        "train_dataset = train_dataset.repeat()\n",
        "iterator = train_dataset.make_one_shot_iterator()\n",
        "train_features, train_labels = iterator.get_next()\n",
        "epoch_num = 10\n",
        "fig, ax = plt.subplots(nrows=epoch_num, ncols=1, figsize = (10, 10 * epoch_num))\n",
        "test_codes = list()\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.train.MonitoredSession() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(epoch_num):\n",
        "    feed = {data: mnist.test.images.reshape([-1, 28, 28])}\n",
        "    test_elbo = sess.run(elbo, feed_dict = feed)\n",
        "    test_codes = sess.run(code, feed_dict = feed)\n",
        "    print('Epoch', epoch, 'elbo', test_elbo)\n",
        "    ax[epoch].set_ylabel('Epoch {}'.format(epoch))\n",
        "    plot_codes(fig, ax[epoch], test_codes, mnist.test.labels)\n",
        "    for _ in range(600):\n",
        "      feed = {data: sess.run(train_features).reshape([-1, 28, 28])}\n",
        "      sess.run(optimize, feed_dict = feed)\n",
        "plt.show()\n",
        "\n",
        "embedding_var = tf.Variable(test_codes, name=NAME_TO_VISUALISE_VARIABLE)\n",
        "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
        "\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = embedding_var.name\n",
        "\n",
        "# Specify where you find the metadata\n",
        "embedding.metadata_path = path_for_mnist_metadata #'metadata.tsv'\n",
        "\n",
        "# Specify where you find the sprite (we will create this later)\n",
        "embedding.sprite.image_path = path_for_mnist_sprites #'mnistdigits.png'\n",
        "embedding.sprite.single_image_dim.extend([28,28])\n",
        "\n",
        "# Say that you want to visualise the embeddings\n",
        "projector.visualize_embeddings(summary_writer, config)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  saver = tf.train.Saver()\n",
        "  saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p13W1CBb5JSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "LOG_DIR = 'embedded_test_sample'\n",
        "NAME_TO_VISUALISE_VARIABLE = \"mnist_embedding\"\n",
        "\n",
        "path_for_mnist_sprites =  os.path.join(LOG_DIR,'mnistdigits.png')\n",
        "path_for_mnist_metadata =  os.path.join(LOG_DIR,'metadata.tsv')\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data/')\n",
        "\n",
        "def create_sprite_image(images):\n",
        "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
        "    if isinstance(images, list):\n",
        "        images = np.array(images)\n",
        "    img_h = images.shape[1]\n",
        "    img_w = images.shape[2]\n",
        "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    \n",
        "    \n",
        "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
        "    \n",
        "    for i in range(n_plots):\n",
        "        for j in range(n_plots):\n",
        "            this_filter = i * n_plots + j\n",
        "            if this_filter < images.shape[0]:\n",
        "                this_img = images[this_filter]\n",
        "                spriteimage[i * img_h:(i + 1) * img_h,\n",
        "                  j * img_w:(j + 1) * img_w] = this_img\n",
        "    \n",
        "    return spriteimage\n",
        "\n",
        "def vector_to_matrix_mnist(mnist_digits):\n",
        "    \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\"\n",
        "    return np.reshape(mnist_digits,(-1,28,28))\n",
        "\n",
        "def invert_grayscale(mnist_digits):\n",
        "    \"\"\" Makes black white, and white black \"\"\"\n",
        "    return 1-mnist_digits\n",
        "  \n",
        "to_visualise = mnist.test.images\n",
        "to_visualise = vector_to_matrix_mnist(to_visualise)\n",
        "to_visualise = invert_grayscale(to_visualise)\n",
        "\n",
        "sprite_image = create_sprite_image(to_visualise)\n",
        "\n",
        "plt.imsave(path_for_mnist_sprites,sprite_image,cmap='gray')\n",
        "plt.imshow(sprite_image,cmap='gray')\n",
        "\n",
        "with open(path_for_mnist_metadata,'w') as f:\n",
        "    f.write(\"Index\\tLabel\\n\")\n",
        "    for index,label in enumerate(mnist.test.labels):\n",
        "        f.write(\"%d\\t%d\\n\" % (index,label))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}